{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import sys\n",
    "from itertools import islice\n",
    "from random import shuffle\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from time import time\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Directory containing raw audio files\n",
    "AUDIO_DIR = '/Volumes/thesis/audio/'\n",
    "# Directory to write features to\n",
    "MFCC_WRITE_DIR = 'data/features/mfcc/'\n",
    "MEL_WRITE_DIR = 'data/features/mel_spec/'\n",
    "MFCC_ALL_WRITE_DIR = 'data/features/mfcc_all_unpadded/'\n",
    "BOW_WRITE_DIR = 'data/features/bow_500/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load AllMusic data\n",
    "artists = pd.read_csv('data/allmusic/artists_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Mel-frequency cepstral coefficient (MFCC) representations of first track for each artist we have audio for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# key is artist id, value is a MFCC representation of first track for artist\n",
    "mfcc_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for artist in tqdm_notebook(os.listdir(AUDIO_DIR)):\n",
    "    first_track = None\n",
    "    \n",
    "    for track in os.listdir(AUDIO_DIR + artist):\n",
    "        # Find the first track (zero-indexed)\n",
    "        if track.startswith('0'):\n",
    "            first_track = track\n",
    "            break\n",
    "    \n",
    "    # Create MFCC representation of track\n",
    "    if first_track is not None:\n",
    "        try:\n",
    "            y, sr = librosa.load(AUDIO_DIR + '{}/{}'.format(artist, first_track))\n",
    "            mfcc_dict[artist] = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)    \n",
    "        except Exception as e:\n",
    "            print e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute maximum dimensions for mfcc feature matrix\n",
    "shapes = []\n",
    "\n",
    "for i, item in mfcc_dict.items():\n",
    "    shapes.append(item.shape)\n",
    "\n",
    "max_dim = np.max(shapes, axis=0)\n",
    "\n",
    "for i, item in mfcc_dict.items():\n",
    "    # Zero pad so that all matrices are the same size\n",
    "    padded = np.zeros(max_dim)\n",
    "    padded[:,:mfcc_dict[i].shape[1]] = mfcc_dict[i]\n",
    "    mfcc_dict[i] = padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write mfcc arrays to files\n",
    "for i, mfcc in tqdm_notebook(mfcc_dict.items()):\n",
    "    np.save(MFCC_WRITE_DIR + '{}.npy'.format(i), mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC Extraction for all tracks for all artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for artist in tqdm_notebook(os.listdir(AUDIO_DIR)):\n",
    "    # Create directory for each artist if it does not exist yet\n",
    "    artist_mfcc_path = MFCC_ALL_WRITE_DIR + artist\n",
    "    \n",
    "    if not os.path.isdir(artist_mfcc_path):\n",
    "        os.makedirs(artist_mfcc_path)\n",
    "    \n",
    "    for track in os.listdir(AUDIO_DIR + artist):\n",
    "        # Create MFCC representation of track\n",
    "        try:\n",
    "            y, sr = librosa.load(AUDIO_DIR + '{}/{}'.format(artist, track))\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "            np.save(artist_mfcc_path + '/{}.npy'.format(track.decode('utf-8').split('.mp3')[0].encode('utf-8')), mfcc)\n",
    "        except Exception as e:\n",
    "            print artist, track\n",
    "            print e\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate mean and standard deviation of each MFCC to normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame_count = 0\n",
    "mfcc_sum = np.zeros(13,)\n",
    "\n",
    "for artist in tqdm_notebook(os.listdir(MFCC_ALL_WRITE_DIR)):\n",
    "    for song in os.listdir(MFCC_ALL_WRITE_DIR + artist):\n",
    "        mfcc = np.load(MFCC_ALL_WRITE_DIR + artist + '/' + song)\n",
    "        mfcc_sum += mfcc.sum(axis=1)\n",
    "        frame_count += mfcc.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f in os.listdir('/Volumes/thesis/features/mfcc_all_unpadded/0001174080'):\n",
    "    np.load('/Volumes/thesis/features/mfcc_all_unpadded/0001174080')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfcc_means = mfcc_sum / frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('kmeans_helpers/mfcc_means.npy', mfcc_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sq_dev_sum = np.zeros(13,)\n",
    "\n",
    "for artist in tqdm_notebook(os.listdir(MFCC_ALL_WRITE_DIR)):\n",
    "    for song in os.listdir(MFCC_ALL_WRITE_DIR + artist):\n",
    "        mfcc = np.load(MFCC_ALL_WRITE_DIR + artist + '/' + song)\n",
    "        sq_dev_sum += ((mfcc.T - mfcc_means.T).T ** 2).sum(axis=1).reshape(-1, 1)\n",
    "        \n",
    "mfcc_stds = np.sqrt(sq_dev_sum / frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('kmeans_helpers/mfcc_stds.npy', mfcc_stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create codebook for normalized MFCCs via streaming kmeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfcc_means = np.load('kmeans_helpers/mfcc_means.npy')\n",
    "mfcc_stds = np.load('kmeans_helpers/mfcc_stds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "\n",
    "for artist in os.listdir(MFCC_ALL_WRITE_DIR):\n",
    "    for song in os.listdir(MFCC_ALL_WRITE_DIR + artist):\n",
    "        paths.append(MFCC_ALL_WRITE_DIR + artist + '/' + song)\n",
    "        \n",
    "# Shuffle path names\n",
    "shuffle(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batch(paths, batch_size=1000):\n",
    "    \"\"\"Given an iterable of paths to mfcc vectors, generate batches for streaming\"\"\"\n",
    "    l = len(paths)\n",
    "    for ndx in range(0, l, batch_size):\n",
    "        yield paths[ndx:min(ndx + batch_size, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting batch 1\n",
      "Fitting batch 2\n",
      "Fitting batch 3\n",
      "Fitting batch 4\n",
      "Fitting batch 5\n",
      "Fitting batch 6\n",
      "Fitting batch 7\n",
      "Fitting batch 8\n",
      "Fitting batch 9\n",
      "Fitting batch 10\n",
      "Fitting batch 11\n",
      "Fitting batch 12\n",
      "Fitting batch 13\n",
      "Fitting batch 14\n",
      "Fitting batch 15\n",
      "Fitting batch 16\n",
      "Fitting batch 17\n",
      "Fitting batch 18\n",
      "Fitting batch 19\n",
      "Fitting batch 20\n",
      "Fitting batch 21\n",
      "Fitting batch 22\n",
      "Fitting batch 23\n",
      "Fitting batch 24\n",
      "Fitting batch 25\n",
      "Fitting batch 26\n",
      "Fitting batch 27\n",
      "Fitting batch 28\n",
      "Fitting batch 29\n",
      "Fitting batch 30\n",
      "Fitting batch 31\n",
      "Fitting batch 32\n",
      "Fitting batch 33\n",
      "Fitting batch 34\n",
      "Fitting batch 35\n",
      "Fitting batch 36\n",
      "Fitting batch 37\n",
      "Fitting batch 38\n",
      "Fitting batch 39\n",
      "Fitting batch 40\n",
      "Fitting batch 41\n",
      "Fitting batch 42\n",
      "Fitting batch 43\n",
      "Fitting batch 44\n",
      "Fitting batch 45\n",
      "Fitting batch 46\n",
      "Fitting batch 47\n",
      "Fitting batch 48\n",
      "Fitting batch 49\n",
      "Fitting batch 50\n",
      "Fitting batch 51\n",
      "Fitting batch 52\n",
      "Fitting batch 53\n",
      "Fitting batch 54\n",
      "Fitting batch 55\n",
      "Fitting batch 56\n",
      "Fitting batch 57\n",
      "Fitting batch 58\n",
      "Fitting batch 59\n",
      "Fitting batch 60\n",
      "Fitting batch 61\n",
      "Fitting batch 62\n",
      "Fitting batch 63\n",
      "Fitting batch 64\n",
      "Fitting batch 65\n",
      "Fitting batch 66\n",
      "Fitting batch 67\n",
      "Fitting batch 68\n",
      "Fitting batch 69\n",
      "Fitting batch 70\n",
      "Fitting batch 71\n",
      "Fitting batch 72\n",
      "Fitting batch 73\n",
      "Fitting batch 74\n",
      "Fitting batch 75\n",
      "Fitting batch 76\n",
      "Fitting batch 77\n",
      "Fitting batch 78\n",
      "Fitting batch 79\n",
      "Fitting batch 80\n",
      "Fitting batch 81\n",
      "Fitting batch 82\n",
      "Fitting batch 83\n",
      "Fitting batch 84\n",
      "Fitting batch 85\n",
      "Fitting batch 86\n",
      "Fitting batch 87\n",
      "Fitting batch 88\n",
      "Fitting batch 89\n",
      "Fitting batch 90\n",
      "Fitting batch 91\n",
      "Fitting batch 92\n",
      "Fitting batch 93\n",
      "Fitting batch 94\n",
      "Fitting batch 95\n",
      "Fitting batch 96\n",
      "Fitting batch 97\n",
      "Fitting batch 98\n",
      "Fitting batch 99\n",
      "Fitting batch 100\n",
      "Fitting batch 101\n",
      "Fitting batch 102\n",
      "Fitting batch 103\n",
      "Fitting batch 104\n",
      "Fitting batch 105\n",
      "Fitting batch 106\n",
      "Fitting batch 107\n",
      "Fitting batch 108\n",
      "Fitting batch 109\n",
      "Fitting batch 110\n",
      "Fitting batch 111\n",
      "Fitting batch 112\n",
      "Fitting batch 113\n",
      "Fitting batch 114\n",
      "Fitting batch 115\n",
      "Fitting batch 116\n",
      "Fitting batch 117\n",
      "Fitting batch 118\n",
      "Fitting batch 119\n",
      "Fitting batch 120\n",
      "Fitting batch 121\n",
      "Fitting batch 122\n",
      "Fitting batch 123\n",
      "Fitting batch 124\n",
      "Fitting batch 125\n",
      "Fitting batch 126\n",
      "Fitting batch 127\n",
      "Fitting batch 128\n",
      "Fitting batch 129\n",
      "Fitting batch 130\n",
      "Fitting batch 131\n",
      "Fitting batch 132\n",
      "Fitting batch 133\n",
      "Fitting batch 134\n",
      "Fitting batch 135\n",
      "Fitting batch 136\n",
      "Fitting batch 137\n",
      "Fitting batch 138\n",
      "Fitting batch 139\n",
      "Fitting batch 140\n",
      "Fitting batch 141\n",
      "Fitting batch 142\n",
      "Fitting batch 143\n",
      "Fitting batch 144\n"
     ]
    }
   ],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=500)\n",
    "count = 0\n",
    "\n",
    "for batch in generate_batch(paths, 1000):\n",
    "    count += 1\n",
    "    print \"Fitting batch\", count\n",
    "    \n",
    "    X = []\n",
    "    \n",
    "    # Read in mfcc vectors and normalize\n",
    "    for path in batch:\n",
    "        # Shape is (13, num_frames)\n",
    "        mfcc = np.load(path)\n",
    "        # Normalize by subtracting mean and dividing by std_dev\n",
    "        mfcc_norm = (mfcc.T - mfcc_means) / mfcc_stds\n",
    "        \n",
    "        for frame in mfcc_norm:\n",
    "            X.append(frame)\n",
    "    \n",
    "    # Update kmeans using batch\n",
    "    kmeans.partial_fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kmeans_helpers/kmeans_500.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(kmeans, 'kmeans_helpers/kmeans_500.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Representation for MFCC features using Kmeans quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f98b91fb6f4a24b3ca9a5e337ff30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for artist in tqdm_notebook(os.listdir(MFCC_ALL_WRITE_DIR)):\n",
    "    # Create directory for each artist if it does not exist yet\n",
    "    artist_bow_path = BOW_WRITE_DIR + artist\n",
    "    \n",
    "    if not os.path.isdir(artist_bow_path):\n",
    "        os.makedirs(artist_bow_path)\n",
    "    \n",
    "    for song in os.listdir(MFCC_ALL_WRITE_DIR + artist):\n",
    "        try:\n",
    "            X = []\n",
    "            bow = [0 for _ in range(500)]\n",
    "\n",
    "            mfcc = np.load(MFCC_ALL_WRITE_DIR + artist + '/' + song)\n",
    "            # Normalize by subtracting mean and dividing by std_dev\n",
    "            mfcc_norm = (mfcc.T - mfcc_means) / mfcc_stds\n",
    "\n",
    "            for frame in mfcc_norm:\n",
    "                X.append(frame)\n",
    "\n",
    "            # Give cluster assignments for each frame\n",
    "            cluster_assign = kmeans.predict(X)\n",
    "            for cluster in cluster_assign:\n",
    "                bow[cluster] += 1\n",
    "\n",
    "            # Save bow feature representation\n",
    "            np.save(BOW_WRITE_DIR + artist + '/{}.npy'.format(song.decode('utf-8').split('.npy')[0].encode('utf-8')), bow)\n",
    "        except:\n",
    "            print 'Failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Mel Spectrogram representations for each first track we have audio for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for artist in tqdm_notebook(os.listdir(AUDIO_DIR)):\n",
    "    first_track = None\n",
    "    \n",
    "    for track in os.listdir(AUDIO_DIR + artist):\n",
    "        # Find the first track (zero-indexed)\n",
    "        if track.startswith('0'):\n",
    "            first_track = track\n",
    "            break\n",
    "    \n",
    "    # Create mel representation of track\n",
    "    if first_track is not None:\n",
    "        try:\n",
    "            y, sr = librosa.load(AUDIO_DIR + '{}/{}'.format(artist, first_track))\n",
    "            mel_spec = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "            # Add zero padding\n",
    "            padded = np.zeros((128, 1298))\n",
    "            padded[:,:mel_spec.shape[1]] = mel_spec\n",
    "            np.save(MEL_WRITE_DIR + '{}.npy'.format(artist), padded)\n",
    "        except Exception as e:\n",
    "            print e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
