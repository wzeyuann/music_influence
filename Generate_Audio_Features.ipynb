{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import sys\n",
    "from itertools import islice\n",
    "from random import shuffle\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from time import time\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Directory containing raw audio files\n",
    "AUDIO_DIR = '/Volumes/thesis/audio/'\n",
    "# Directory to write features to\n",
    "MFCC_WRITE_DIR = 'data/features/mfcc/'\n",
    "MEL_WRITE_DIR = 'data/features/mel_spec/'\n",
    "MFCC_ALL_WRITE_DIR = '/Volumes/thesis/features/mfcc_all_unpadded/'\n",
    "BOW_WRITE_DIR = '/Volumes/thesis/features/bow_1000/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load AllMusic data\n",
    "artists = pd.read_csv('data/allmusic/artists_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Mel-frequency cepstral coefficient (MFCC) representations of first track for each artist we have audio for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# key is artist id, value is a MFCC representation of first track for artist\n",
    "mfcc_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61a6b6f578d47808c715b93a04522e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for artist in tqdm_notebook(os.listdir(AUDIO_DIR)):\n",
    "    first_track = None\n",
    "    \n",
    "    for track in os.listdir(AUDIO_DIR + artist):\n",
    "        # Find the first track (zero-indexed)\n",
    "        if track.startswith('0'):\n",
    "            first_track = track\n",
    "            break\n",
    "    \n",
    "    # Create MFCC representation of track\n",
    "    if first_track is not None:\n",
    "        try:\n",
    "            y, sr = librosa.load(AUDIO_DIR + '{}/{}'.format(artist, first_track))\n",
    "            mfcc_dict[artist] = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)    \n",
    "        except Exception as e:\n",
    "            print e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute maximum dimensions for mfcc feature matrix\n",
    "shapes = []\n",
    "\n",
    "for i, item in mfcc_dict.items():\n",
    "    shapes.append(item.shape)\n",
    "\n",
    "max_dim = np.max(shapes, axis=0)\n",
    "\n",
    "for i, item in mfcc_dict.items():\n",
    "    # Zero pad so that all matrices are the same size\n",
    "    padded = np.zeros(max_dim)\n",
    "    padded[:,:mfcc_dict[i].shape[1]] = mfcc_dict[i]\n",
    "    mfcc_dict[i] = padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8079e900864e82bfa82a134bac7ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Write mfcc arrays to files\n",
    "for i, mfcc in tqdm_notebook(mfcc_dict.items()):\n",
    "    np.save(MFCC_WRITE_DIR + '{}.npy'.format(i), mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC Extraction for all tracks for all artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f105de392be34c81a188a6c4bc1bb910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000021009 3_No More Heroes.mp3\n",
      "\n",
      "0000033286 1_Trip to New Orleans.mp3\n",
      "\n",
      "0000036367 6_The Great Out There.mp3\n",
      "\n",
      "0000053204 3_Não Quero Saber Mais Dela.mp3\n",
      "\n",
      "0000057073 0_Poison in Your Brain.mp3\n",
      "\n",
      "0000059537 9_Saturday Freedom.mp3\n",
      "\n",
      "0000070349 3_It Will Be Alright With Me.mp3\n",
      "\n",
      "0000071514 2_Fussing and Fighting.mp3\n",
      "\n",
      "0000078160 7_New Forms.mp3\n",
      "\n",
      "0000082831 3_I'm Making Believe.mp3\n",
      "\n",
      "0000083097 1_Break the Silence.mp3\n",
      "\n",
      "0000102964 8_Fuck America.mp3\n",
      "\n",
      "0000104035 8_That's Where My Money Goes.mp3\n",
      "\n",
      "0000107139 3_Don't Let 'Em.mp3\n",
      "\n",
      "0000125528 9_Cocaine Cool [Extended Vol. 2].mp3\n",
      "\n",
      "0000127044 4_Jeepers Creepers.mp3\n",
      "\n",
      "0000157314 5_Throw Your Hands.mp3\n",
      "\n",
      "0000159052 5_The Weight.mp3\n",
      "\n",
      "0000159697 4_Ten Toes Down.mp3\n",
      "\n",
      "0000161173 8_Interviews.mp3\n",
      "\n",
      "0000169341 2_Menage a Trois.mp3\n",
      "\n",
      "0000178345 5_Don't Wann Fall in Love.mp3\n",
      "\n",
      "0000178852 3_Gotta Get Mine.mp3\n",
      "\n",
      "0000180228 3_Rip It Up.mp3\n",
      "\n",
      "0000190951 9_Atomic Bass Cats.mp3\n",
      "\n",
      "0000194875 4_Sleepin' on My Couch.mp3\n",
      "\n",
      "0000195868 5_Funk Yard.mp3\n",
      "\n",
      "0000198783 1_I'm Coming Home.mp3\n",
      "\n",
      "0000216116 2_Metro.mp3\n",
      "\n",
      "0000223197 1_Drag My Body.mp3\n",
      "\n",
      "0000223197 5_Exister.mp3\n",
      "\n",
      "0000227607 1_Cold Lonely Nights.mp3\n",
      "\n",
      "0000246172 3_Je Suis Content.mp3\n",
      "\n",
      "0000273239 7_Can I Get Witcha.mp3\n",
      "\n",
      "0000277061 5_Deni Kelen Be Koko (Lonely Girl by the Riverside).mp3\n",
      "\n",
      "0000277061 6_Jugu (Enemy).mp3\n",
      "\n",
      "0000287995 1_Crime of Passion.mp3\n",
      "\n",
      "0000289986 5_Dig That Crazy Chick.mp3\n",
      "\n",
      "0000297559 0_The Pearly Blues.mp3\n",
      "\n",
      "0000304555 4_Side of the Road.mp3\n",
      "\n",
      "0000321126 0_Must Be the Music.mp3\n",
      "\n",
      "0000346684 5_Seek It.mp3\n",
      "\n",
      "0000380458 6_Indian Momma.mp3\n",
      "\n",
      "0000394557 9_Would You Leave Me Alone, Little Darling.mp3\n",
      "\n",
      "0000400717 4_Under the Weeping Moon.mp3\n",
      "\n",
      "0000416986 2_Friends.mp3\n",
      "\n",
      "0000417607 6_There There Betty Betty.mp3\n",
      "\n",
      "0000423267 8_Itchycoo Park.mp3\n",
      "\n",
      "0000477494 7_He Will Break Your Heart.mp3\n",
      "\n",
      "0000480154 3_A Midnight Farewell.mp3\n",
      "\n",
      "0000490265 6_Hung Up on Losin'.mp3\n",
      "\n",
      "0000490265 9_Once Again.mp3\n",
      "\n",
      "0000501435 5_A Chorus Line.mp3\n",
      "\n",
      "0000524814 1_Rock & Roll Boogie.mp3\n",
      "\n",
      "0000536794 7_É Mentira, Oi.mp3\n",
      "\n",
      "0000546205 6_Iemanja.mp3\n",
      "\n",
      "0000558942 2_Toggle.mp3\n",
      "\n",
      "0000562949 8_138 Trek.mp3\n",
      "\n",
      "0000570046 4_Black Kiss.mp3\n",
      "\n",
      "0000575051 4_Dandy.mp3\n",
      "\n",
      "0000576030 1_Rock the Show.mp3\n",
      "\n",
      "0000580294 6_Start the Commotion.mp3\n",
      "\n",
      "0000590044 9_Article One.mp3\n",
      "\n",
      "0000600977 8_Doin' Damage to My Native Language.mp3\n",
      "\n",
      "0000614137 1_Here Comes My Girl.mp3\n",
      "\n",
      "0000615119 0_Diamonds on My Windshield.mp3\n",
      "\n",
      "0000622604 9_Dusic.mp3\n",
      "\n",
      "0000630439 2_It Ain't Necessarily So (Interlude).mp3\n",
      "\n",
      "0000631395 8_Birds on High.mp3\n",
      "\n",
      "0000638740 7_(I Think I'll Take A) Walk Around the World.mp3\n",
      "\n",
      "0000661026 1_What We Do.mp3\n",
      "\n",
      "0000665324 0_Psychic Bounty Killaz.mp3\n",
      "\n",
      "0000750129 1_Detroit After Dark.mp3\n",
      "\n",
      "0000752151 1_Chaos.mp3\n",
      "\n",
      "0000759998 1_Cipater.mp3\n",
      "\n",
      "0000762523 7_Can I Get a Lil' Luv.mp3\n",
      "\n",
      "0000762595 9_My Brutha.mp3\n",
      "\n",
      "0000763341 8_Flea Circus.mp3\n",
      "\n",
      "0000772721 6_Nights Over Egypt.mp3\n",
      "\n",
      "0000789514 5_Maldito Callo.mp3\n",
      "\n",
      "0000791618 3_Paper Chace.mp3\n",
      "\n",
      "0000793465 2_Paid the Price.mp3\n",
      "\n",
      "0000804430 2_Reggae Kumbia.mp3\n",
      "\n",
      "0000812450 2_One More Bump.mp3\n",
      "\n",
      "0000833539 3_Let's Get Down.mp3\n",
      "\n",
      "0000852698 5_Here We Go Again.mp3\n",
      "\n",
      "0000883499 8_Street Life.mp3\n",
      "\n",
      "0000886267 5_Runnin the Show.mp3\n",
      "\n",
      "0000962064 9_Buddy's Blues.mp3\n",
      "\n",
      "0000978433 7_In Da Streets.mp3\n",
      "\n",
      "0000983740 4_El Usurero del Amor.mp3\n",
      "\n",
      "0001343538 5_Black Gangster.mp3\n",
      "\n",
      "0002289132 2_You Got What I Like.mp3\n",
      "\n",
      "0002539021 0_Lezgo Vip [Justin Martin Vs. Ardalan].mp3\n",
      "\n",
      "0002839284 6_Colours of the Fall.mp3\n",
      "\n",
      "0002870109 8_Barren Hill.mp3\n",
      "\n",
      "0002917594 0_Pleasure and Pain.mp3\n",
      "\n",
      "0002917594 1_Wanted Man.mp3\n",
      "\n",
      "0002917594 3_Check It Out.mp3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for artist in tqdm_notebook(os.listdir(AUDIO_DIR)):\n",
    "    # Create directory for each artist if it does not exist yet\n",
    "    artist_mfcc_path = MFCC_ALL_WRITE_DIR + artist\n",
    "    \n",
    "    if not os.path.isdir(artist_mfcc_path):\n",
    "        os.makedirs(artist_mfcc_path)\n",
    "    \n",
    "    for track in os.listdir(AUDIO_DIR + artist):\n",
    "        # Create MFCC representation of track\n",
    "        try:\n",
    "            y, sr = librosa.load(AUDIO_DIR + '{}/{}'.format(artist, track))\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "            np.save(artist_mfcc_path + '/{}.npy'.format(track.decode('utf-8').split('.mp3')[0].encode('utf-8')), mfcc)\n",
    "        except Exception as e:\n",
    "            print artist, track\n",
    "            print e\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate mean and standard deviation of each MFCC to normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ef48ad90474ea98bcb11832cc5163d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot reshape array of size 502 into shape (13,1291)\n",
      "/Volumes/thesis/features/mfcc_all_unpadded/0001173733/9_Shotgun Joe.npy\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 6] Device not configured: '/Volumes/thesis/features/mfcc_all_unpadded/0001174080'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-3c7fde8fd1f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0martist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMFCC_ALL_WRITE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msong\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMFCC_ALL_WRITE_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mmfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMFCC_ALL_WRITE_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0martist\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 6] Device not configured: '/Volumes/thesis/features/mfcc_all_unpadded/0001174080'"
     ]
    }
   ],
   "source": [
    "frame_count = 0\n",
    "mfcc_sum = np.zeros(13,)\n",
    "\n",
    "for artist in tqdm_notebook(os.listdir(MFCC_ALL_WRITE_DIR)):\n",
    "    for song in os.listdir(MFCC_ALL_WRITE_DIR + artist):\n",
    "        mfcc = np.load(MFCC_ALL_WRITE_DIR + artist + '/' + song)\n",
    "        mfcc_sum += mfcc.sum(axis=1)\n",
    "        frame_count += mfcc.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"0_I Don't Wanna Go to Sleep Again.npy\",\n",
       " '1_Follow the Bouncing Ball.npy',\n",
       " '2_Uptown, Uptempo Woman.npy',\n",
       " \"3_Today I Killed a Man I Didn't Know.npy\",\n",
       " '4_We Stand Closer Together.npy',\n",
       " \"5_I Don't Wanna Go to Sleep Again.npy\",\n",
       " '6_The Storm.npy',\n",
       " '7_I Wonder.npy',\n",
       " '8_A Way of Life.npy',\n",
       " '9_Sweet America.npy']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for f in os.listdir('/Volumes/thesis/features/mfcc_all_unpadded/0001174080'):\n",
    "    np.load('/Volumes/thesis/features/mfcc_all_unpadded/0001174080')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfcc_means = mfcc_sum / frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('kmeans_helpers/mfcc_means.npy', mfcc_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_dev_sum = np.zeros(13,)\n",
    "\n",
    "for artist in tqdm_notebook(os.listdir(MFCC_ALL_WRITE_DIR)):\n",
    "    for song in os.listdir(MFCC_ALL_WRITE_DIR + artist):\n",
    "        mfcc = np.load(MFCC_ALL_WRITE_DIR + artist + '/' + song)\n",
    "        sq_dev_sum += ((mfcc.T - mfcc_means.T).T ** 2).sum(axis=1).reshape(-1, 1)\n",
    "        \n",
    "mfcc_stds = np.sqrt(sq_dev_sum / frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('kmeans_helpers/mfcc_stds.npy', mfcc_stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create codebook for normalized MFCCs via streaming kmeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "\n",
    "for artist in os.listdir(MFCC_ALL_WRITE_DIR):\n",
    "    for song in os.listdir(MFCC_ALL_WRITE_DIR + artist):\n",
    "        paths.append(MFCC_ALL_WRITE_DIR + artist + '/' + song)\n",
    "        \n",
    "# Shuffle path names\n",
    "shuffle(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batch(paths, batch_size=1000):\n",
    "    \"\"\"Given an iterable of paths to mfcc vectors, generate batches for streaming\"\"\"\n",
    "    l = len(paths)\n",
    "    for ndx in range(0, l, batch_size):\n",
    "        yield paths[ndx:min(ndx + batch_size, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting batch 1\n",
      "Fitting batch 2\n",
      "Fitting batch 3\n",
      "Fitting batch 4\n",
      "Fitting batch 5\n",
      "Fitting batch 6\n",
      "Fitting batch 7\n",
      "Fitting batch 8\n",
      "Fitting batch 9\n",
      "Fitting batch 10\n",
      "Fitting batch 11\n",
      "Fitting batch 12\n",
      "Fitting batch 13\n",
      "Fitting batch 14\n",
      "Fitting batch 15\n",
      "Fitting batch 16\n",
      "Fitting batch 17\n",
      "Fitting batch 18\n",
      "Fitting batch 19\n",
      "Fitting batch 20\n",
      "[MiniBatchKMeans] Reassigning 4 cluster centers.\n",
      "Fitting batch 21\n",
      "Fitting batch 22\n",
      "Fitting batch 23\n",
      "Fitting batch 24\n",
      "Fitting batch 25\n",
      "Fitting batch 26\n",
      "Fitting batch 27\n",
      "Fitting batch 28\n",
      "Fitting batch 29\n",
      "Fitting batch 30\n",
      "Fitting batch 31\n",
      "Fitting batch 32\n",
      "Fitting batch 33\n",
      "Fitting batch 34\n",
      "Fitting batch 35\n",
      "Fitting batch 36\n",
      "Fitting batch 37\n",
      "Fitting batch 38\n",
      "Fitting batch 39\n",
      "Fitting batch 40\n",
      "Fitting batch 41\n",
      "Fitting batch 42\n",
      "Fitting batch 43\n",
      "Fitting batch 44\n",
      "Fitting batch 45\n",
      "Fitting batch 46\n",
      "Fitting batch 47\n",
      "Fitting batch 48\n",
      "Fitting batch 49\n",
      "Fitting batch 50\n",
      "Fitting batch 51\n",
      "Fitting batch 52\n",
      "Fitting batch 53\n",
      "Fitting batch 54\n",
      "Fitting batch 55\n",
      "Fitting batch 56\n",
      "Fitting batch 57\n",
      "Fitting batch 58\n",
      "Fitting batch 59\n",
      "Fitting batch 60\n",
      "Fitting batch 61\n",
      "Fitting batch 62\n",
      "Fitting batch 63\n",
      "Fitting batch 64\n",
      "Fitting batch 65\n",
      "Fitting batch 66\n",
      "Fitting batch 67\n",
      "Fitting batch 68\n",
      "Fitting batch 69\n",
      "Fitting batch 70\n",
      "Fitting batch 71\n",
      "Fitting batch 72\n",
      "Fitting batch 73\n",
      "Fitting batch 74\n",
      "Fitting batch 75\n",
      "Fitting batch 76\n",
      "Fitting batch 77\n",
      "Fitting batch 78\n",
      "Fitting batch 79\n",
      "Fitting batch 80\n",
      "Fitting batch 81\n",
      "Fitting batch 82\n",
      "Fitting batch 83\n",
      "Fitting batch 84\n",
      "Fitting batch 85\n",
      "Fitting batch 86\n",
      "Fitting batch 87\n",
      "Fitting batch 88\n",
      "Fitting batch 89\n",
      "Fitting batch 90\n",
      "Fitting batch 91\n",
      "Fitting batch 92\n",
      "Fitting batch 93\n",
      "Fitting batch 94\n",
      "Fitting batch 95\n",
      "Fitting batch 96\n",
      "Fitting batch 97\n",
      "Fitting batch 98\n",
      "Fitting batch 99\n",
      "Fitting batch 100\n",
      "Fitting batch 101\n",
      "Fitting batch 102\n",
      "Fitting batch 103\n",
      "Fitting batch 104\n",
      "Fitting batch 105\n",
      "Fitting batch 106\n",
      "Fitting batch 107\n",
      "Fitting batch 108\n",
      "Fitting batch 109\n",
      "Fitting batch 110\n",
      "Fitting batch 111\n",
      "Fitting batch 112\n",
      "Fitting batch 113\n",
      "Fitting batch 114\n",
      "Fitting batch 115\n",
      "Fitting batch 116\n",
      "Fitting batch 117\n",
      "Fitting batch 118\n",
      "Fitting batch 119\n",
      "Fitting batch 120\n",
      "Fitting batch 121\n",
      "Fitting batch 122\n",
      "Fitting batch 123\n",
      "Fitting batch 124\n",
      "Fitting batch 125\n",
      "Fitting batch 126\n",
      "Fitting batch 127\n",
      "Fitting batch 128\n",
      "Fitting batch 129\n",
      "Fitting batch 130\n",
      "Fitting batch 131\n",
      "Fitting batch 132\n",
      "Fitting batch 133\n",
      "Fitting batch 134\n",
      "Fitting batch 135\n",
      "Fitting batch 136\n",
      "Fitting batch 137\n",
      "Fitting batch 138\n",
      "Fitting batch 139\n",
      "Fitting batch 140\n",
      "Fitting batch 141\n",
      "Fitting batch 142\n",
      "Fitting batch 143\n",
      "Fitting batch 144\n"
     ]
    }
   ],
   "source": [
    "kmeans = MiniBatchKMeans(verbose=True, n_clusters=1000)\n",
    "count = 0\n",
    "\n",
    "for batch in generate_batch(paths, 1000):\n",
    "    count += 1\n",
    "    print \"Fitting batch\", count\n",
    "    \n",
    "    X = []\n",
    "    \n",
    "    # Read in mfcc vectors and normalize\n",
    "    for path in batch:\n",
    "        # Shape is (13, num_frames)\n",
    "        mfcc = np.load(path)\n",
    "        # Normalize by subtracting mean and dividing by std_dev\n",
    "        mfcc_norm = (mfcc.T - mfcc_means) / mfcc_stds\n",
    "        \n",
    "        for frame in mfcc_norm:\n",
    "            X.append(frame)\n",
    "    \n",
    "    # Update kmeans using batch\n",
    "    kmeans.partial_fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kmeans_helpers/kmeans_1000.pkl']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(kmeans, 'kmeans_helpers/kmeans_1000.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Representation for MFCC features using Kmeans quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e56ecb77474abca2056daca8c025bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for artist in tqdm_notebook(os.listdir(MFCC_ALL_WRITE_DIR)):\n",
    "    # Create directory for each artist if it does not exist yet\n",
    "    artist_bow_path = BOW_WRITE_DIR + artist\n",
    "    \n",
    "    if not os.path.isdir(artist_bow_path):\n",
    "        os.makedirs(artist_bow_path)\n",
    "    \n",
    "    for song in os.listdir(MFCC_ALL_WRITE_DIR + artist):\n",
    "        try:\n",
    "            X = []\n",
    "            bow = [0 for _ in range(1000)]\n",
    "\n",
    "            mfcc = np.load(MFCC_ALL_WRITE_DIR + artist + '/' + song)\n",
    "            # Normalize by subtracting mean and dividing by std_dev\n",
    "            mfcc_norm = (mfcc.T - mfcc_means) / mfcc_stds\n",
    "\n",
    "            for frame in mfcc_norm:\n",
    "                X.append(frame)\n",
    "\n",
    "            # Give cluster assignments for each frame\n",
    "            cluster_assign = kmeans.predict(X)\n",
    "            for cluster in cluster_assign:\n",
    "                bow[cluster] += 1\n",
    "\n",
    "            # Save bow feature representation\n",
    "            np.save(BOW_WRITE_DIR + artist + '/{}.npy'.format(song.decode('utf-8').split('.npy')[0].encode('utf-8')), bow)\n",
    "        except:\n",
    "            print e.message, e.args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Mel Spectrogram representations for each first track we have audio for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e440b2ca2d848b5bd1a2b64e6369765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for artist in tqdm_notebook(os.listdir(AUDIO_DIR)):\n",
    "    first_track = None\n",
    "    \n",
    "    for track in os.listdir(AUDIO_DIR + artist):\n",
    "        # Find the first track (zero-indexed)\n",
    "        if track.startswith('0'):\n",
    "            first_track = track\n",
    "            break\n",
    "    \n",
    "    # Create mel representation of track\n",
    "    if first_track is not None:\n",
    "        try:\n",
    "            y, sr = librosa.load(AUDIO_DIR + '{}/{}'.format(artist, first_track))\n",
    "            mel_spec = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "            # Add zero padding\n",
    "            padded = np.zeros((128, 1298))\n",
    "            padded[:,:mel_spec.shape[1]] = mel_spec\n",
    "            np.save(MEL_WRITE_DIR + '{}.npy'.format(artist), padded)\n",
    "        except Exception as e:\n",
    "            print e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
