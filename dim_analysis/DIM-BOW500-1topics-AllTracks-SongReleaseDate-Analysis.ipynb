{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, utils\n",
    "from gensim.models.wrappers.dtmmodel import DtmModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from copy import copy\n",
    "from collections import OrderedDict\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = '../models/dim_bow500_1topics_alltracks_songreleasedate'\n",
    "BOW_DIR = '../data/features/bow_500/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "dim_model = DtmModel.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load artist info\n",
    "artists = pd.read_csv('../data/allmusic/artists_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load song info\n",
    "songs = pd.read_csv('../data/artist_song_list_years_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load bow_path_by_artist\n",
    "bow_path_by_artist = pickle.load(open('../models/dim_bow500_1topics_alltracks_songreleasedatebow_paths.pk', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_path_by_artist_new = []\n",
    "\n",
    "for (id, path, year) in bow_path_by_artist:\n",
    "    bow_path_by_artist_new.append((id, BOW_DIR + path, year))\n",
    "\n",
    "bow_path_by_artist = bow_path_by_artist_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of artists per each time slice:\n",
      "[1, 1, 1, 2, 1, 3, 1, 3, 3, 12, 13, 6, 7, 21, 28, 23, 19, 9, 5, 10, 2, 11, 17, 13, 16, 15, 16, 25, 38, 13, 36, 54, 55, 47, 41, 51, 61, 67, 65, 114, 153, 297, 421, 405, 476, 475, 411, 453, 474, 560, 554, 717, 801, 878, 954, 995, 1038, 1001, 1136, 1207, 1066, 1196, 1288, 1251, 1367, 1435, 1573, 1483, 1500, 1560, 1372, 1576, 1582, 1524, 1679, 1706, 1839, 1941, 2201, 2530, 2616, 2977, 3341, 3404, 3832, 3641, 3820, 3935, 3723, 4236, 4058, 3828, 4035, 3903, 3637, 2903, 2992, 2751, 2719, 3122, 3586, 2583, 2588, 1722, 12]\n"
     ]
    }
   ],
   "source": [
    "# Order list by year\n",
    "bow_path_by_artist.sort(key= lambda x: songs[songs['artist_id'] == x[0]]['year'].iloc[0])\n",
    "\n",
    "# Create counter for number of songs for each year \n",
    "year_counter = {int(k) : 0 for k in np.unique(zip(*bow_path_by_artist)[2])}\n",
    "\n",
    "for id, path, year in bow_path_by_artist:\n",
    "    year_counter[year] += 1\n",
    "\n",
    "# Lookup table for time_slice index v. year\n",
    "time_slice_dict = {idx : year for (idx, year) in enumerate(sorted(year_counter))}\n",
    "# List of counts for each time slice for DIM\n",
    "time_seq = [year_counter[key] for key in sorted(year_counter.keys())]\n",
    "\n",
    "print \"Count of artists per each time slice:\"\n",
    "print time_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get most influential songs for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create (num_songs, num_topics) array of influence scores\n",
    "song_topic_inf_matrix = []\n",
    "\n",
    "for time_idx in range(len(dim_model.time_slices)):    \n",
    "    for song_idx in range(dim_model.time_slices[time_idx]):\n",
    "        song_inf_by_topic = [None] * dim_model.num_topics\n",
    "\n",
    "        for topic_idx in range(dim_model.num_topics):\n",
    "            song_inf_by_topic[topic_idx] = dim_model.influences_time[time_idx][song_idx][topic_idx]\n",
    "        \n",
    "        song_topic_inf_matrix.append(song_inf_by_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0\n",
      "Liaisons Dangereuses\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 20] Not a directory: '../data/features/bow_1000/0000225039/9_Etre Assis Ou Danser.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-522853c66f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0martists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbow_path_by_artist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0martist_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Lookup name of sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_path_by_artist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0martist_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 20] Not a directory: '../data/features/bow_1000/0000225039/9_Etre Assis Ou Danser.npy'"
     ]
    }
   ],
   "source": [
    "# Get the indices of the most influential songs per topic\n",
    "most_inf_idx = np.array(song_topic_inf_matrix).argmax(axis=0)\n",
    "\n",
    "for topic_no, artist_idx in enumerate(most_inf_idx):\n",
    "    print \"Topic:\", topic_no\n",
    "    # Lookup artist name\n",
    "    print artists[artists['id'] == bow_path_by_artist[artist_idx][0]]['name'].iloc[0]\n",
    "    # Lookup name of sample\n",
    "    print os.listdir(bow_path_by_artist[artist_idx][1])[0]\n",
    "    \n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get most influential songs per topic per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_topic_inf_by_year = []\n",
    "song_topic_inf_matrix_copy = copy(song_topic_inf_matrix)\n",
    "\n",
    "# Slice song-topic matrix into list of submatrices keyed by time slice\n",
    "for time_idx, num_in_slice in enumerate(dim_model.time_slices):\n",
    "    song_topic_inf_by_year.append(song_topic_inf_matrix_copy[:num_in_slice])\n",
    "    del song_topic_inf_matrix_copy[:num_in_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx, song_topic_matrix in enumerate(song_topic_inf_by_year):\n",
    "    print time_slice_dict[idx], ':', time_seq[idx], 'songs'\n",
    "    print \"===============================\"\n",
    "\n",
    "    # Get the indices of the most influential songs per topic\n",
    "    # Note: Need to adjust indexing since index resets to 0 for each new year\n",
    "    most_inf_idx = np.array(song_topic_matrix).argmax(axis=0) + sum(dim_model.time_slices[:idx])\n",
    "\n",
    "    for topic_no, artist_idx in enumerate(most_inf_idx):\n",
    "        print \"Topic:\", topic_no\n",
    "        # Lookup artist name\n",
    "        print artists[artists['id'] == bow_path_by_artist[artist_idx][0]]['name'].iloc[0]\n",
    "        # Lookup name of sample\n",
    "        print os.listdir(bow_path_by_artist[artist_idx][1])[0]\n",
    "        print artists[artists['id'] == bow_path_by_artist[artist_idx][0]]['main_genre'].iloc[0]\n",
    "        print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation with AllMusic Influence Graph Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate max DIM influence per artist\n",
    "max_dim_influences = np.array(song_topic_inf_matrix).max(axis=1)\n",
    "\n",
    "# Get list of artist outdegrees in same order\n",
    "artist_ids_ordered = [t[0] for t in bow_path_by_artist]\n",
    "outdegrees_ordered = []\n",
    "\n",
    "for id in artist_ids_ordered:\n",
    "    outdegrees_ordered.append(artists[artists['id'] == id]['outdegree'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.13039411477493498, pvalue=1.9843723917550392e-56)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create df\n",
    "artist_influences_df = pd.DataFrame({'id':artist_ids_ordered, 'outdegree':outdegrees_ordered, 'influence':max_dim_influences})\n",
    "# Group by artist_id and take mean to get mean influence per artist\n",
    "mean_inf_df = artist_influences_df.groupby(by='id').mean()\n",
    "# Calculate correlation\n",
    "spearmanr(mean_inf_df['influence'].values, mean_inf_df['outdegree'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Breakdown by Genre"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
